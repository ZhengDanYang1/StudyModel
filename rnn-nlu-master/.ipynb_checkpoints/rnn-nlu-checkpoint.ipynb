{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Parameters:\n",
      "max_gradient_norm: 5.0\n",
      "batch_size: 16\n",
      "size: 128\n",
      "word_embedding_size: 128\n",
      "num_layers: 1\n",
      "in_vocab_size: 10000\n",
      "out_vocab_size: 10000\n",
      "data_dir: data/ATIS_samples\n",
      "train_dir: model_tmp\n",
      "max_train_data_size: 0\n",
      "steps_per_checkpoint: 100\n",
      "max_training_steps: 30000\n",
      "max_test_data_size: 0\n",
      "use_attention: True\n",
      "max_sequence_length: 50\n",
      "dropout_keep_prob: 0.5\n",
      "bidirectional_rnn: True\n",
      "task: joint\n",
      "Preparing data in data/ATIS_samples\n",
      "{'_PAD': 0, '_UNK': 1, 'to': 2, 'from': 3, 'the': 4, 'boston': 5, 'on': 6, 'round': 7, 'trip': 8, 'atlanta': 9, \"what's\": 10, 'lowest': 11, 'fare': 12, 'dallas': 13, 'find': 14, 'me': 15, 'earliest': 16, 'flight': 17, 'any': 18, 'day': 19, 'of': 20, 'week': 21, 'display': 22, 'all': 23, 'flights': 24, 'baltimore': 25, 'july': 26, 'thirty': 27, 'first': 28, 'economy': 29, 'fares': 30, 'new': 31, 'york': 32, 'miami': 33, 'i': 34, 'need': 35, 'fly': 36, 'denver': 37, 'san': 38, 'francisco': 39, 'and': 40, 'back': 41}\n",
      "{'_PAD': 0, '_UNK': 1, 'O': 2, 'B-toloc.city_name': 3, 'B-fromloc.city_name': 4, 'B-round_trip': 5, 'I-round_trip': 6, 'B-cost_relative': 7, 'B-flight_mod': 8, 'B-depart_date.month_name': 9, 'B-depart_date.day_number': 10, 'I-depart_date.day_number': 11, 'B-economy': 12, 'I-fromloc.city_name': 13, 'I-toloc.city_name': 14}\n",
      "{'_UNK': 0, 'airfare': 1, 'flight': 2}\n",
      "2019-11-27 20:28:57.412903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-11-27 20:28:57.412947: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-11-27 20:28:57.412955: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-11-27 20:28:57.412963: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-11-27 20:28:57.412971: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-11-27 20:28:58.098832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \n",
      "name: TITAN Xp\n",
      "major: 6 minor: 1 memoryClockRate (GHz) 1.582\n",
      "pciBusID 0000:82:00.0\n",
      "Total memory: 11.91GiB\n",
      "Free memory: 11.76GiB\n",
      "2019-11-27 20:28:58.098877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n",
      "2019-11-27 20:28:58.098888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n",
      "2019-11-27 20:28:58.098901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:82:00.0)\n",
      "Max sequence length:  [(50, 50)]\n",
      "Creating 1 layers of 128 units.\n",
      "buckets [(50, 50)]\n",
      "Use the attention RNN model\n",
      "buckets [(50, 50)]\n",
      "Use the attention RNN model\n",
      "Reading model parameters from model_tmp/model.ckpt-30000\n",
      "Creating model with source_vocab_size=42, target_vocab_size=15, label_vocab_size=3.\n",
      "Reading train/valid/test data (training set limit: 0).\n",
      "data_set [[]]\n",
      "source 34 1 2 36 3 5 1 1 1 40 1 1 37 1 1 1 4 1\n",
      "\n",
      "source_ids [34, 1, 2, 36, 3, 5, 1, 1, 1, 40, 1, 1, 37, 1, 1, 1, 4, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [1, 24, 1, 1, 3, 1, 2, 25, 6, 1, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [1, 1, 4, 1, 1, 1, 38, 39, 1, 4, 1, 1, 17, 1, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [1, 1, 3, 1, 2, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [7, 8, 30, 3, 1, 2, 1, 1, 1, 1]\n",
      "_buckets [(50, 50)]\n",
      "data_set [[]]\n",
      "source 34 1 1 2 14 1 17 3 1 2 1 1 1 1 1 1 1 1 1\n",
      "\n",
      "source_ids [34, 1, 1, 2, 14, 1, 17, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [6, 1, 28, 34, 35, 1, 1, 3, 1, 2, 38, 1, 1, 1, 1, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [6, 1, 28, 34, 35, 1, 17, 1, 3, 1, 2, 38, 1]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [34, 1, 1, 1, 17, 1, 1, 1, 3, 1, 2, 38, 1, 6, 1, 28]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [34, 1, 1, 1, 17, 3, 1, 2, 1, 1, 1, 1, 1, 28, 6, 1, 1]\n",
      "_buckets [(50, 50)]\n",
      "data_set [[]]\n",
      "source 10 4 11 7 8 12 3 13 2 9\n",
      "\n",
      "source_ids [10, 4, 11, 7, 8, 12, 3, 13, 2, 9]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [14, 15, 4, 16, 17, 3, 5, 2, 9, 6, 18, 19, 20, 4, 21]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [22, 23, 24, 3, 5, 2, 25, 6, 26, 27, 28]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [29, 30, 31, 32, 2, 33, 7, 8]\n",
      "_buckets [(50, 50)]\n",
      "source_ids [34, 35, 2, 36, 3, 5, 2, 37, 6, 2, 38, 39, 40, 41]\n",
      "_buckets [(50, 50)]\n"
     ]
    }
   ],
   "source": [
    "!python run_multi-task_rnn.py --data_dir data/ATIS_samples \\\n",
    "      --train_dir model_tmp\\\n",
    "      --max_sequence_length 50 \\\n",
    "      --task \"joint\" \\\n",
    "      --bidirectional_rnn True \\\n",
    "      --use_attention True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
