{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNNEmbedding:\n",
    "    def __init__(self, config):\n",
    "        self.char_vocab_size = config[\"char_vocab_size\"]\n",
    "        self.char_embedding_dim = config[\"char_embedding_dim\"]\n",
    "\n",
    "        self.kernel_sizes = config[\"kernel_sizes\"]\n",
    "        self.filter_size = config[\"elmo_hidden\"] // len(self.kernel_sizes)\n",
    "\n",
    "        self.seq_len = config[\"word_seq_len\"]\n",
    "        self.char_seq_len = config[\"char_seq_len\"]\n",
    "        \n",
    "        with tf.variable_scope(\"char_cnn\", reuse=tf.AUTO_REUSE):\n",
    "            self.conv_filters = [\n",
    "                tf.layers.Conv1D(self.filter_size, kernel_size)\n",
    "                for kernel_size in self.kernel_sizes\n",
    "            ]\n",
    "\n",
    "        with tf.variable_scope(\"char_embedding\", reuse=tf.AUTO_REUSE):\n",
    "            self.embedding_weight = tf.get_variable(\"embedding_weight\", \n",
    "                                        [self.char_vocab_size, self.char_embedding_dim],\n",
    "                                        dtype=tf.float32)\n",
    "            \n",
    "            \n",
    "    def forward(self, data):\n",
    "        embed_input = tf.nn.embedding_lookup(self.embedding_weight, data[\"input\"])\n",
    "\n",
    "        conv_outputs = []\n",
    "        conv_input = tf.reshape(embed_input, [-1, self.char_seq_len, self.char_embedding_dim])\n",
    "        for conv, kernel_size in zip(self.conv_filters, self.kernel_sizes):\n",
    "            conv_output = conv(conv_input)\n",
    "            _conv_output = tf.reshape(conv_output, [-1, self.seq_len, conv_output.shape[1], self.filter_size])\n",
    "\n",
    "            pool_output = tf.nn.max_pool(_conv_output, [1, 1, conv_output.shape[1], 1], [1, 1, 1, 1], 'VALID')\n",
    "            pool_output = tf.squeeze(pool_output, axis=2)\n",
    "            conv_outputs.append(pool_output)\n",
    "\n",
    "        # shape = (batch_size, seq_len, embedding_dim)\n",
    "        char_word_embedding = tf.concat(conv_outputs, axis=2)\n",
    "        return char_word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMO:\n",
    "    def __init__(self, config):\n",
    "        self.embedding = CharCNNEmbedding(config)\n",
    "        self.hidden_size = config[\"elmo_hidden\"]\n",
    "        self.vocab_size = config[\"word_vocab_size\"]\n",
    "        self.seq_len = config[\"word_seq_len\"]\n",
    "        self.config = config\n",
    "        \n",
    "        with tf.variable_scope(\"elmo_rnn_cell\"):\n",
    "            self.forward_cell = tf.nn.rnn_cell.LSTMCell(self.hidden_size, reuse=tf.AUTO_REUSE)\n",
    "            self.backward_cell = tf.nn.rnn_cell.LSTMCell(self.hidden_size, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "        #是否将输入concat到输出\n",
    "        if config.get(\"use_skip_connection\"):\n",
    "            self.forward_cell = tf.nn.rnn_cell.ResidualWrapper(self.forward_cell)\n",
    "            self.backward_cell = tf.nn.rnn_cell.ResidualWrapper(self.backward_cell)\n",
    "            \n",
    "        with tf.variable_scope(\"elmo_softmax\"):\n",
    "            softmax_weight_shape = [config[\"word_vocab_size\"], config[\"elmo_hidden\"]]\n",
    "\n",
    "            self.forward_softmax_w = tf.get_variable(\"forward_softmax_w\", softmax_weight_shape, dtype=tf.float32)\n",
    "            self.backward_softmax_w = tf.get_variable(\"backward_softmax_w\", softmax_weight_shape, dtype=tf.float32)\n",
    "\n",
    "            self.forward_softmax_b = tf.get_variable(\"forward_softmax_b\", [config[\"word_vocab_size\"]])\n",
    "            self.backward_softmax_b = tf.get_variable(\"backward_softmax_b\", [config[\"word_vocab_size\"]])\n",
    "            \n",
    "    def forward(self, data):\n",
    "        embedding_output = self.embedding.forward(data)\n",
    "        with tf.variable_scope(\"elmo_rnn_forward\"):\n",
    "            forward_outputs, forward_states = tf.nn.dynamic_rnn(self.forward_cell,\n",
    "                                                                inputs=embedding_output,\n",
    "                                                                sequence_length=data[\"input_len\"],\n",
    "                                                                dtype=tf.float32)\n",
    "\n",
    "        with tf.variable_scope(\"elmo_rnn_backward\"):\n",
    "            backward_outputs, backward_states = tf.nn.dynamic_rnn(self.backward_cell,\n",
    "                                                                  inputs=embedding_output,\n",
    "                                                                  sequence_length=data[\"input_len\"],\n",
    "                                                                  dtype=tf.float32)\n",
    "\n",
    "        # # Concatenate the forward and backward LSTM output\n",
    "        forward_projection = tf.matmul(forward_outputs, tf.expand_dims(tf.transpose(self.forward_softmax_w), 0))\n",
    "        forward_projection = tf.nn.bias_add(forward_projection, self.forward_softmax_b)\n",
    "\n",
    "        backward_projection = tf.matmul(backward_outputs, tf.expand_dims(tf.transpose(self.backward_softmax_w), 0))\n",
    "        backward_projection = tf.nn.bias_add(backward_projection, self.backward_softmax_b)\n",
    "\n",
    "        return forward_outputs, backward_outputs, forward_projection, backward_projection\n",
    "    \n",
    "    \n",
    "    def train(self, data, global_step_variable=None):\n",
    "        forward_output, backward_output, _, _ = self.forward(data)\n",
    "\n",
    "        forward_target = data[\"target\"]\n",
    "        forward_pred = tf.cast(tf.argmax(tf.nn.softmax(forward_output, -1), -1), tf.int32)\n",
    "        forward_correct = tf.equal(forward_pred, forward_target)\n",
    "        forward_padding = tf.sequence_mask(data[\"target_len\"], maxlen=self.seq_len, dtype=tf.float32)\n",
    "\n",
    "        forward_softmax_target = tf.cast(tf.reshape(forward_target, [-1, 1]), tf.int64)\n",
    "        forward_softmax_input = tf.reshape(forward_output, [-1, self.hidden_size])\n",
    "        forward_train_loss = tf.nn.sampled_softmax_loss(\n",
    "            weights=self.forward_softmax_w, biases=self.forward_softmax_b,\n",
    "            labels=forward_softmax_target, inputs=forward_softmax_input,\n",
    "            num_sampled=self.config[\"softmax_sample_size\"],\n",
    "            num_classes=self.config[\"word_vocab_size\"]\n",
    "        )\n",
    "\n",
    "        forward_train_loss = tf.reshape(forward_train_loss, [-1, self.seq_len])\n",
    "        forward_train_loss = tf.multiply(forward_train_loss, forward_padding)\n",
    "        forward_train_loss = tf.reduce_mean(forward_train_loss)\n",
    "\n",
    "        backward_target = tf.reverse_sequence(data[\"target\"], data[\"target_len\"], seq_axis=1, batch_axis=0)\n",
    "        backward_pred = tf.cast(tf.argmax(tf.nn.softmax(backward_output, -1), -1), tf.int32)\n",
    "        backward_correct = tf.equal(backward_pred, backward_target)\n",
    "        backward_padding = tf.sequence_mask(data[\"target_len\"], maxlen=self.seq_len, dtype=tf.float32)\n",
    "\n",
    "        backward_softmax_target = tf.cast(tf.reshape(backward_target, [-1, 1]), tf.int64)\n",
    "        backward_softmax_input = tf.reshape(backward_output, [-1, self.hidden_size])\n",
    "        backward_train_loss = tf.nn.sampled_softmax_loss(\n",
    "            weights=self.backward_softmax_w, biases=self.backward_softmax_b,\n",
    "            labels=backward_softmax_target, inputs=backward_softmax_input,\n",
    "            num_sampled=self.config[\"softmax_sample_size\"],\n",
    "            num_classes=self.config[\"word_vocab_size\"]\n",
    "        )\n",
    "\n",
    "        backward_train_loss = tf.reshape(backward_train_loss, [-1, self.seq_len])\n",
    "        backward_train_loss = tf.multiply(backward_train_loss, backward_padding)\n",
    "        backward_train_loss = tf.reduce_mean(backward_train_loss)\n",
    "\n",
    "        train_loss = forward_train_loss + backward_train_loss\n",
    "        train_correct = tf.concat([forward_correct, backward_correct], axis=-1)\n",
    "        train_acc = tf.reduce_mean(tf.cast(train_correct, tf.float32))\n",
    "\n",
    "        tf.summary.scalar(\"train_acc\", train_acc)\n",
    "        tf.summary.scalar(\"train_loss\", train_loss)\n",
    "\n",
    "        train_ops = tf.train.AdamOptimizer().minimize(train_loss)\n",
    "        return train_loss, train_acc, train_ops\n",
    "\n",
    "    def pred(self, data):\n",
    "        elmo_projection_output = self.forward(data)\n",
    "        eval_output = tf.nn.softmax(elmo_projection_output, dim=-1)\n",
    "        return eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1024, 'corpus_files': ['data/corpus/elmo.corpus.xlarge.1.txt'], 'epochs': 10, 'verbose_freq': 1, 'word_vocab_path': 'data/vocab/word.90k.vocab', 'char_vocab_path': 'data/vocab/jamo.100.vocab', 'word_seq_len': 10, 'char_seq_len': 7, 'char_embedding_dim': 64, 'kernel_sizes': [1, 2, 3, 4], 'filter_sizes': None, 'elmo_hidden': 512, 'softmax_sample_size': 8196, 'prefetch_size': 1024, 'log_dir': 'logs/', 'save_freq': 1000, 'model_save_path': 'output/elmo.model.test', 'log_file_prefix': 'elmo.log'}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-b\", \"--batch_size\", type=int, default=1024)\n",
    "parser.add_argument(\"-c\", \"--corpus_files\", nargs='+', type=str,\n",
    "                    default=[\"data/corpus/elmo.corpus.xlarge.1.txt\"])\n",
    "\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--verbose_freq\", type=int, default=1)\n",
    "\n",
    "parser.add_argument(\"--word_vocab_path\", type=str, default=\"data/vocab/word.90k.vocab\")\n",
    "parser.add_argument(\"--char_vocab_path\", type=str, default=\"data/vocab/jamo.100.vocab\")\n",
    "\n",
    "parser.add_argument(\"--word_seq_len\", type=int, default=10)\n",
    "parser.add_argument(\"--char_seq_len\", type=int, default=7)\n",
    "\n",
    "parser.add_argument(\"--char_embedding_dim\", type=int, default=64)\n",
    "parser.add_argument(\"--kernel_sizes\", nargs='+', type=int, default=[1, 2, 3, 4])\n",
    "parser.add_argument(\"--filter_sizes\", nargs='+', type=int, default=None)\n",
    "\n",
    "parser.add_argument(\"--elmo_hidden\", type=int, default=512)\n",
    "parser.add_argument(\"--softmax_sample_size\", type=int, default=8196)\n",
    "\n",
    "parser.add_argument(\"--prefetch_size\", type=int, default=1024)\n",
    "\n",
    "parser.add_argument(\"--log_dir\", type=str, default=\"logs/\")\n",
    "parser.add_argument(\"--save_freq\", type=int, default=1000)\n",
    "parser.add_argument(\"--model_save_path\", type=str, default=\"output/elmo.model.test\")\n",
    "parser.add_argument(\"--log_file_prefix\", type=str, default=\"elmo.log\")\n",
    "args = parser.parse_known_args()[0]\n",
    "config_dict = vars(args)\n",
    "\n",
    "print(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from han2jamo import Han2Jamo\n",
    "from vocab_builder import CharWordVocab, WordVocab\n",
    "\n",
    "\n",
    "class ElmoKoreanDataset:\n",
    "    def __init__(self, config):\n",
    "        self.corpus_files = config[\"corpus_files\"]\n",
    "        self.jamo_processor = Han2Jamo()\n",
    "\n",
    "        self.char_vocab = CharWordVocab.load_vocab(config[\"char_vocab_path\"])\n",
    "        self.word_vocab = WordVocab.load_vocab(config[\"word_vocab_path\"])\n",
    "\n",
    "        self.seq_len = config[\"word_seq_len\"]\n",
    "        self.char_seq_len = config[\"char_seq_len\"]\n",
    "        self.corpus_size = self.get_corpus_size()\n",
    "        print(\"Dataset Size:\", self.corpus_size)\n",
    "\n",
    "        config[\"char_vocab_size\"] = len(self.char_vocab)\n",
    "        config[\"word_vocab_size\"] = len(self.word_vocab)\n",
    "\n",
    "    def text_to_char_sequence(self, text):\n",
    "        jamo_text = self.jamo_processor.str_to_jamo(text)\n",
    "        char_idx_seq, seq_len = self.char_vocab.to_seq(jamo_text,\n",
    "                                                       char_seq_len=self.char_seq_len,\n",
    "                                                       seq_len=self.seq_len,\n",
    "                                                       with_len=True)\n",
    "        seq_len = self.seq_len if seq_len > self.seq_len else seq_len\n",
    "        return char_idx_seq, seq_len\n",
    "\n",
    "    def text_to_word_sequence(self, text):\n",
    "        word_idx_seq, seq_len = self.word_vocab.to_seq(text, seq_len=self.seq_len + 1, with_len=True, with_eos=True)\n",
    "        seq_len = self.seq_len + 1 if seq_len > self.seq_len + 1 else seq_len\n",
    "        word_idx_seq, seq_len = word_idx_seq[1:], seq_len - 1\n",
    "        return word_idx_seq, seq_len\n",
    "\n",
    "    def produce_data(self, text):\n",
    "        text = text.strip()\n",
    "        char_word_input, input_len = self.text_to_char_sequence(text)\n",
    "        word_target, target_len = self.text_to_word_sequence(text)\n",
    "\n",
    "        return {\"input\": char_word_input, \"input_len\": input_len,\n",
    "                \"target\": word_target, \"target_len\": target_len}\n",
    "\n",
    "    def data_generator(self):\n",
    "        for file_path in self.corpus_files:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for text in f:\n",
    "                    yield self.produce_data(text)\n",
    "\n",
    "    def get_corpus_size(self):\n",
    "        count = 0\n",
    "        for file_path in self.corpus_files:\n",
    "            with open(file_path) as file:\n",
    "                count += sum(1 for _ in file)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MODELS_DIR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7ceab1fad9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODELS_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcustom_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimestepDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCamouflage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHighway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSampledSoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MODELS_DIR'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Input, SpatialDropout1D\n",
    "from keras.layers import LSTM, CuDNNLSTM, Activation\n",
    "from keras.layers import Lambda, Embedding, Conv2D, GlobalMaxPool1D\n",
    "from keras.layers import add, concatenate\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.constraints import MinMaxNorm\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from data import MODELS_DIR\n",
    "from .custom_layers import TimestepDropout, Camouflage, Highway, SampledSoftmax\n",
    "\n",
    "\n",
    "class ELMo(object):\n",
    "    def __init__(self, parameters):\n",
    "        self._model = None\n",
    "        self._elmo_model = None\n",
    "        self.parameters = parameters\n",
    "        self.compile_elmo()\n",
    "\n",
    "    def __del__(self):\n",
    "        K.clear_session()\n",
    "        del self._model\n",
    "\n",
    "    def char_level_token_encoder(self):\n",
    "        charset_size = self.parameters['charset_size']\n",
    "        char_embedding_size = self.parameters['char_embedding_size']\n",
    "        token_embedding_size = self.parameters['hidden_units_size']\n",
    "        n_highway_layers = self.parameters['n_highway_layers']\n",
    "        filters = self.parameters['cnn_filters']\n",
    "        token_maxlen = self.parameters['token_maxlen']\n",
    "\n",
    "        # Input Layer, word characters (samples, words, character_indices)\n",
    "        inputs = Input(shape=(None, token_maxlen,), dtype='int32')\n",
    "        # Embed characters (samples, words, characters, character embedding)\n",
    "        embeds = Embedding(input_dim=charset_size, output_dim=char_embedding_size)(inputs)\n",
    "        token_embeds = []\n",
    "        # Apply multi-filter 2D convolutions + 1D MaxPooling + tanh\n",
    "        for (window_size, filters_size) in filters:\n",
    "            convs = Conv2D(filters=filters_size, kernel_size=[window_size, char_embedding_size], strides=(1, 1),\n",
    "                           padding=\"same\")(embeds)\n",
    "            convs = TimeDistributed(GlobalMaxPool1D())(convs)\n",
    "            convs = Activation('tanh')(convs)\n",
    "            convs = Camouflage(mask_value=0)(inputs=[convs, inputs])\n",
    "            token_embeds.append(convs)\n",
    "        token_embeds = concatenate(token_embeds)\n",
    "        # Apply highways networks\n",
    "        for i in range(n_highway_layers):\n",
    "            token_embeds = TimeDistributed(Highway())(token_embeds)\n",
    "            token_embeds = Camouflage(mask_value=0)(inputs=[token_embeds, inputs])\n",
    "        # Project to token embedding dimensionality\n",
    "        token_embeds = TimeDistributed(Dense(units=token_embedding_size, activation='linear'))(token_embeds)\n",
    "        token_embeds = Camouflage(mask_value=0)(inputs=[token_embeds, inputs])\n",
    "\n",
    "        token_encoder = Model(inputs=inputs, outputs=token_embeds, name='token_encoding')\n",
    "        return token_encoder\n",
    "\n",
    "    def compile_elmo(self, print_summary=False):\n",
    "        \"\"\"\n",
    "        Compiles a Language Model RNN based on the given parameters\n",
    "        \"\"\"\n",
    "\n",
    "        if self.parameters['token_encoding'] == 'word':\n",
    "            # Train word embeddings from scratch\n",
    "            word_inputs = Input(shape=(None,), name='word_indices', dtype='int32')\n",
    "            embeddings = Embedding(self.parameters['vocab_size'], self.parameters['hidden_units_size'], trainable=True, name='token_encoding')\n",
    "            inputs = embeddings(word_inputs)\n",
    "\n",
    "            # Token embeddings for Input\n",
    "            drop_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(inputs)\n",
    "            lstm_inputs = TimestepDropout(self.parameters['word_dropout_rate'])(drop_inputs)\n",
    "\n",
    "            # Pass outputs as inputs to apply sampled softmax\n",
    "            next_ids = Input(shape=(None, 1), name='next_ids', dtype='float32')\n",
    "            previous_ids = Input(shape=(None, 1), name='previous_ids', dtype='float32')\n",
    "        elif self.parameters['token_encoding'] == 'char':\n",
    "            # Train character-level representation\n",
    "            word_inputs = Input(shape=(None, self.parameters['token_maxlen'],), dtype='int32', name='char_indices')\n",
    "            inputs = self.char_level_token_encoder()(word_inputs)\n",
    "\n",
    "            # Token embeddings for Input\n",
    "            drop_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(inputs)\n",
    "            lstm_inputs = TimestepDropout(self.parameters['word_dropout_rate'])(drop_inputs)\n",
    "\n",
    "            # Pass outputs as inputs to apply sampled softmax\n",
    "            next_ids = Input(shape=(None, 1), name='next_ids', dtype='float32')\n",
    "            previous_ids = Input(shape=(None, 1), name='previous_ids', dtype='float32')\n",
    "\n",
    "        # Reversed input for backward LSTMs\n",
    "        re_lstm_inputs = Lambda(function=ELMo.reverse)(lstm_inputs)\n",
    "        mask = Lambda(function=ELMo.reverse)(drop_inputs)\n",
    "\n",
    "        # Forward LSTMs\n",
    "        for i in range(self.parameters['n_lstm_layers']):\n",
    "            if self.parameters['cuDNN']:\n",
    "                lstm = CuDNNLSTM(units=self.parameters['lstm_units_size'], return_sequences=True,\n",
    "                                 kernel_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n",
    "                                                              self.parameters['cell_clip']),\n",
    "                                 recurrent_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n",
    "                                                                 self.parameters['cell_clip']))(lstm_inputs)\n",
    "            else:\n",
    "                lstm = LSTM(units=self.parameters['lstm_units_size'], return_sequences=True, activation=\"tanh\",\n",
    "                            recurrent_activation='sigmoid',\n",
    "                            kernel_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n",
    "                                                         self.parameters['cell_clip']),\n",
    "                            recurrent_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n",
    "                                                            self.parameters['cell_clip'])\n",
    "                            )(lstm_inputs)\n",
    "            lstm = Camouflage(mask_value=0)(inputs=[lstm, drop_inputs])\n",
    "            # Projection to hidden_units_size\n",
    "            proj = TimeDistributed(Dense(self.parameters['hidden_units_size'], activation='linear',\n",
    "                                         kernel_constraint=MinMaxNorm(-1 * self.parameters['proj_clip'],\n",
    "                                                                      self.parameters['proj_clip'])\n",
    "                                         ))(lstm)\n",
    "            # Merge Bi-LSTMs feature vectors with the previous ones\n",
    "            lstm_inputs = add([proj, lstm_inputs], name='f_block_{}'.format(i + 1))\n",
    "            # Apply variational drop-out between BI-LSTM layers\n",
    "            lstm_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(lstm_inputs)\n",
    "\n",
    "        # Backward LSTMs\n",
    "        for i in range(self.parameters['n_lstm_layers']):\n",
    "            if self.parameters['cuDNN']:\n",
    "                re_lstm = CuDNNLSTM(units=self.parameters['lstm_units_size'], return_sequences=True,\n",
    "                                    kernel_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n",
    "                                                                 self.parameters['cell_clip']),\n",
    "                                    recurrent_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n",
    "                                                                    self.parameters['cell_clip']))(re_lstm_inputs)\n",
    "            else:\n",
    "                re_lstm = LSTM(units=self.parameters['lstm_units_size'], return_sequences=True, activation='tanh',\n",
    "                               recurrent_activation='sigmoid',\n",
    "                               kernel_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n",
    "                                                            self.parameters['cell_clip']),\n",
    "                               recurrent_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n",
    "                                                               self.parameters['cell_clip'])\n",
    "                               )(re_lstm_inputs)\n",
    "            re_lstm = Camouflage(mask_value=0)(inputs=[re_lstm, mask])\n",
    "            # Projection to hidden_units_size\n",
    "            re_proj = TimeDistributed(Dense(self.parameters['hidden_units_size'], activation='linear',\n",
    "                                            kernel_constraint=MinMaxNorm(-1 * self.parameters['proj_clip'],\n",
    "                                                                         self.parameters['proj_clip'])\n",
    "                                            ))(re_lstm)\n",
    "            # Merge Bi-LSTMs feature vectors with the previous ones\n",
    "            re_lstm_inputs = add([re_proj, re_lstm_inputs], name='b_block_{}'.format(i + 1))\n",
    "            # Apply variational drop-out between BI-LSTM layers\n",
    "            re_lstm_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(re_lstm_inputs)\n",
    "\n",
    "        # Reverse backward LSTMs' outputs = Make it forward again\n",
    "        re_lstm_inputs = Lambda(function=ELMo.reverse, name=\"reverse\")(re_lstm_inputs)\n",
    "\n",
    "        # Project to Vocabulary with Sampled Softmax\n",
    "        sampled_softmax = SampledSoftmax(num_classes=self.parameters['vocab_size'],\n",
    "                                         num_sampled=int(self.parameters['num_sampled']),\n",
    "                                         tied_to=embeddings if self.parameters['weight_tying']\n",
    "                                         and self.parameters['token_encoding'] == 'word' else None)\n",
    "        outputs = sampled_softmax([lstm_inputs, next_ids])\n",
    "        re_outputs = sampled_softmax([re_lstm_inputs, previous_ids])\n",
    "\n",
    "        self._model = Model(inputs=[word_inputs, next_ids, previous_ids],\n",
    "                            outputs=[outputs, re_outputs])\n",
    "        self._model.compile(optimizer=Adagrad(lr=self.parameters['lr'], clipvalue=self.parameters['clip_value']),\n",
    "                            loss=None)\n",
    "        if print_summary:\n",
    "            self._model.summary()\n",
    "\n",
    "    def train(self, train_data, valid_data):\n",
    "\n",
    "        # Add callbacks (early stopping, model checkpoint)\n",
    "        weights_file = os.path.join(MODELS_DIR, \"elmo_best_weights.hdf5\")\n",
    "        save_best_model = ModelCheckpoint(filepath=weights_file, monitor='val_loss', verbose=1,\n",
    "                                          save_best_only=True, mode='auto')\n",
    "        early_stopping = EarlyStopping(patience=self.parameters['patience'], restore_best_weights=True)\n",
    "\n",
    "        t_start = time.time()\n",
    "\n",
    "        # Fit Model\n",
    "        self._model.fit_generator(train_data,\n",
    "                                  validation_data=valid_data,\n",
    "                                  epochs=self.parameters['epochs'],\n",
    "                                  workers=self.parameters['n_threads']\n",
    "                                  if self.parameters['n_threads'] else os.cpu_count(),\n",
    "                                  use_multiprocessing=True\n",
    "                                  if self.parameters['multi_processing'] else False,\n",
    "                                  callbacks=[save_best_model])\n",
    "\n",
    "        print('Training took {0} sec'.format(str(time.time() - t_start)))\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "\n",
    "        def unpad(x, y_true, y_pred):\n",
    "            y_true_unpad = []\n",
    "            y_pred_unpad = []\n",
    "            for i, x_i in enumerate(x):\n",
    "                for j, x_ij in enumerate(x_i):\n",
    "                    if x_ij == 0:\n",
    "                        y_true_unpad.append(y_true[i][:j])\n",
    "                        y_pred_unpad.append(y_pred[i][:j])\n",
    "                        break\n",
    "            return np.asarray(y_true_unpad), np.asarray(y_pred_unpad)\n",
    "\n",
    "        # Generate samples\n",
    "        x, y_true_forward, y_true_backward = [], [], []\n",
    "        for i in range(len(test_data)):\n",
    "            test_batch = test_data[i][0]\n",
    "            x.extend(test_batch[0])\n",
    "            y_true_forward.extend(test_batch[1])\n",
    "            y_true_backward.extend(test_batch[2])\n",
    "        x = np.asarray(x)\n",
    "        y_true_forward = np.asarray(y_true_forward)\n",
    "        y_true_backward = np.asarray(y_true_backward)\n",
    "\n",
    "        # Predict outputs\n",
    "        y_pred_forward, y_pred_backward = self._model.predict([x, y_true_forward, y_true_backward])\n",
    "\n",
    "        # Unpad sequences\n",
    "        y_true_forward, y_pred_forward = unpad(x, y_true_forward, y_pred_forward)\n",
    "        y_true_backward, y_pred_backward = unpad(x, y_true_backward, y_pred_backward)\n",
    "\n",
    "        # Compute and print perplexity\n",
    "        print('Forward Langauge Model Perplexity: {}'.format(ELMo.perplexity(y_pred_forward, y_true_forward)))\n",
    "        print('Backward Langauge Model Perplexity: {}'.format(ELMo.perplexity(y_pred_backward, y_true_backward)))\n",
    "\n",
    "    def wrap_multi_elmo_encoder(self, print_summary=False, save=False):\n",
    "        \"\"\"\n",
    "        Wrap ELMo meta-model encoder, which returns an array of the 3 intermediate ELMo outputs\n",
    "        :param print_summary: print a summary of the new architecture\n",
    "        :param save: persist model\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        elmo_embeddings = list()\n",
    "        elmo_embeddings.append(concatenate([self._model.get_layer('token_encoding').output, self._model.get_layer('token_encoding').output],\n",
    "                                           name='elmo_embeddings_level_0'))\n",
    "        for i in range(self.parameters['n_lstm_layers']):\n",
    "            elmo_embeddings.append(concatenate([self._model.get_layer('f_block_{}'.format(i + 1)).output,\n",
    "                                                Lambda(function=ELMo.reverse)\n",
    "                                                (self._model.get_layer('b_block_{}'.format(i + 1)).output)],\n",
    "                                               name='elmo_embeddings_level_{}'.format(i + 1)))\n",
    "\n",
    "        camos = list()\n",
    "        for i, elmo_embedding in enumerate(elmo_embeddings):\n",
    "            camos.append(Camouflage(mask_value=0.0, name='camo_elmo_embeddings_level_{}'.format(i + 1))([elmo_embedding,\n",
    "                                                                                                         self._model.get_layer(\n",
    "                                                                                                             'token_encoding').output]))\n",
    "\n",
    "        self._elmo_model = Model(inputs=[self._model.get_layer('word_indices').input], outputs=camos)\n",
    "\n",
    "        if print_summary:\n",
    "            self._elmo_model.summary()\n",
    "\n",
    "        if save:\n",
    "            self._elmo_model.save(os.path.join(MODELS_DIR, 'ELMo_Encoder.hd5'))\n",
    "            print('ELMo Encoder saved successfully')\n",
    "\n",
    "    def save(self, sampled_softmax=True):\n",
    "        \"\"\"\n",
    "        Persist model in disk\n",
    "        :param sampled_softmax: reload model using the full softmax function\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if not sampled_softmax:\n",
    "            self.parameters['num_sampled'] = self.parameters['vocab_size']\n",
    "        self.compile_elmo()\n",
    "        self._model.load_weights(os.path.join(MODELS_DIR, 'elmo_best_weights.hdf5'))\n",
    "        self._model.save(os.path.join(MODELS_DIR, 'ELMo_LM_EVAL.hd5'))\n",
    "        print('ELMo Language Model saved successfully')\n",
    "\n",
    "    def load(self):\n",
    "        self._model = load_model(os.path.join(MODELS_DIR, 'ELMo_LM.h5'),\n",
    "                                 custom_objects={'TimestepDropout': TimestepDropout,\n",
    "                                                 'Camouflage': Camouflage})\n",
    "\n",
    "    def load_elmo_encoder(self):\n",
    "        self._elmo_model = load_model(os.path.join(MODELS_DIR, 'ELMo_Encoder.hd5'),\n",
    "                                      custom_objects={'TimestepDropout': TimestepDropout,\n",
    "                                                      'Camouflage': Camouflage})\n",
    "\n",
    "    def get_outputs(self, test_data, output_type='word', state='last'):\n",
    "        \"\"\"\n",
    "       Wrap ELMo meta-model encoder, which returns an array of the 3 intermediate ELMo outputs\n",
    "       :param test_data: data generator\n",
    "       :param output_type: \"word\" for word vectors or \"sentence\" for sentence vectors\n",
    "       :param state: 'last' for 2nd LSTMs outputs or 'mean' for mean-pooling over inputs, 1st LSTMs and 2nd LSTMs\n",
    "       :return: None\n",
    "       \"\"\"\n",
    "        # Generate samples\n",
    "        x = []\n",
    "        for i in range(len(test_data)):\n",
    "            test_batch = test_data[i][0]\n",
    "            x.extend(test_batch[0])\n",
    "\n",
    "        preds = np.asarray(self._elmo_model.predict(np.asarray(x)))\n",
    "        if state == 'last':\n",
    "            elmo_vectors = preds[-1]\n",
    "        else:\n",
    "            elmo_vectors = np.mean(preds, axis=0)\n",
    "\n",
    "        if output_type == 'words':\n",
    "            return elmo_vectors\n",
    "        else:\n",
    "            return np.mean(elmo_vectors, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def reverse(inputs, axes=1):\n",
    "        return K.reverse(inputs, axes=axes)\n",
    "\n",
    "    @staticmethod\n",
    "    def perplexity(y_pred, y_true):\n",
    "\n",
    "        cross_entropies = []\n",
    "        for y_pred_seq, y_true_seq in zip(y_pred, y_true):\n",
    "            # Reshape targets to one-hot vectors\n",
    "            y_true_seq = to_categorical(y_true_seq, y_pred_seq.shape[-1])\n",
    "            # Compute cross_entropy for sentence words\n",
    "            cross_entropy = K.categorical_crossentropy(K.tf.convert_to_tensor(y_true_seq, dtype=K.tf.float32),\n",
    "                                                       K.tf.convert_to_tensor(y_pred_seq, dtype=K.tf.float32))\n",
    "            cross_entropies.extend(cross_entropy.eval(session=K.get_session()))\n",
    "\n",
    "        # Compute mean cross_entropy and perplexity\n",
    "        cross_entropy = np.mean(np.asarray(cross_entropies), axis=-1)\n",
    "\n",
    "        return pow(2.0, cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
